***

#### LR 应用经验



##### LR-SVM-GBDT对比：

- LR能以概率的形式输出结果，而非只是0和1的判定。SVM的输出原本只能是0和1，是用来做分类的，可以通过一定的方法拿到概率，比如拟合点到超平面的距离。
- LR的可解释性强，可以从拟合结果中直观看到权重，可以看到那个特征对最终的影响大小，可空度非常高，通过观察可以随时调整权重。一般用来做基线版本。
- 训练快，GBDT样本量级不能太大，但是GBDT可以输连续值。通过一些技巧将特征打到更高的维度时（离散化等），LR的训练速度非常快（比GBDT快）。
- LR的结果是概率，可以用来做一个排序模型。
- 添加特征非常简单。



##### 关于样本处理：

1. 样本量太大怎么办？

   - 可以对特征作离散化，用one-hot编码把特征处理成0，1值，收敛速度会快很多。

   - 如果非要用连续值，可以 做scaling，也就是幅度变化。如果不做幅度变化，当有些特征非常大，比如房子面积，有些特侦比较小，如房间数，则画出来的等高线会变成一个椭圆，在计算梯度的时候不是特别准确，导致收敛特别慢或者来回振荡。

   - 试试并行化平台，spark。

   - 如果没有并行化平台，可以试试采样（采样方式：日期or用户or行为），不能随机取，在大样本情况下，随机取会破坏掉数据分布规律。

     

2. 注意样本的平衡

   - 对样本分布非常敏感。
   - 下采样（样本量非常足，但是样本不均衡，那个类别样本多对那个采样），上采样（样本量非常不足，那个样本不足对那个样本做重复或者对称，镜像和旋转等操作）。
   -  修改loss function，给不同权重（可能会导致损失函数非凸）。如果负样本特别少，可以将负样本的权重加大，所以计算出来的负样本损失很大，正样本判断对了还不够，需要很努力将负样本也判断正确。
   - 如果进行了采样，需要对采样后的predict结果进行还原，用作排序时很ok，用作判定请还原。

> 如何做还原？
>
> 
>
> ##### 关于特征处理：
>
> 1. 离散化
>
>    - 离散化其实是将特征映射到高维空间，用线性的LR在高维空间中速度会更快，且兼具更好的分割性。（对连续的数值按照一定的间隔做切分，当数值落在某个间隔中，此处的值填1，其余的全填0。）
>
>    - 稀疏化之后的结果都是0和1，其在做向量内积乘法运算时速度非常快，计算结果也方便存储（存1就好啦，0不需要）。
>
>    - 离散化后，给线性模型带来了一定的非线性。例如，在坦泰尼克号救人中，以年龄为例，小孩和老人更容易获救，所以小孩和老人拿到的权重大，而中间一部分拿到的权重少，此时就有了一定的非线性。切开后，可以分段给权重。
>
>    - 模型稳定，收敛度更高，鲁棒性更好。
>
>    - 在一定程度上降低过拟合。当离散化后，其认为在某个间隔内的数据都是一样的。
>
>      
>
> 2. 非常适合通过组合特征引入个性化因素。
>
>    
>
> 3. 注意特征的频度 
>
>    - 可以区分特征的重要度。
>
>    - 可以产出层次判定模型。明确特征的重要性和不重要性，拿出来放到别的模型中去用。
>
>      
>
> 4. 聚类/Hash
>
>    - 增强了极度稀疏的特征表达能力。比如每个用户有一个uuid，10亿个用户就有10亿个号，基本没什么用，所以可以对uuid做一个聚类，可能品好相近的人会被分到一个类别中，用类别去替代uuid，可以查看一类人的喜好。
>
>    - 减小模型，加速运算。
>
>      
>
> ##### 关于算法调优：
>
> 1. 假设只看模型
>
>    - 选择合适的正则化。
>
>      L1：
>      $$
>      \sum|{\theta_i}|
>      $$
>      L2：
>      $$
>      \sum{\theta_i}^2
>      $$
>      工业上可能会用L1 + L2。
>
>    - 选择合适的正则化系数C，C太大导致所有的考量都集中到正则化上了，C过小导致约束不住波动。
>
>    - 收敛的阈值e，迭代到什么程度时停止。e太大时训练时间太长，而且不一定能达到。
>
>    - 调整loss function给定不同的权重（样本分布不均匀时）。
>
>    - Bagging或其他方式的模型融合（投票原理，会降低过拟合）。
>
>    - 最优化算法选择(‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’)。小样本liblinear，大样本sag，多分类‘newton-cg’和
>      ‘lbfgs’(当然你也可以用liblinear和sag的one-vs-rest)。
>
>      
>
> 2. Liblinear，一个库，台湾大学
>
>    - libsvm稀疏向量存储格式（只会存有值得那些特征），海量数据下单机速度还OK。
>
>    - 高维度离散化特征，准确率逼近非线性切分。
>
>    -  参数调节比较方便。
>
>      
>
> 3. Sklearn中的LR实际上是liblinear封装的

> 